{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMxOGR21FoKyjd04rFJMBWn",
      "include_colab_link": false
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df1d579d910343a890b02d0990720f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b74f54f254f843ef95e204deb9a84351",
              "IPY_MODEL_2a8aaa0b629f4ee18ced954ffec066a2",
              "IPY_MODEL_d5ca88ce7b0444b882baeed48db4c499"
            ],
            "layout": "IPY_MODEL_886858947f4a40ad93f2f5b285b698bd"
          }
        },
        "b74f54f254f843ef95e204deb9a84351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3970522ad6454c728dc31f790d97d701",
            "placeholder": "​",
            "style": "IPY_MODEL_2b688d7d19f34b158c7f8390b5c01192",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "2a8aaa0b629f4ee18ced954ffec066a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08dd39ce39c4b0ba07b208de9c8577e",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2be35c569d27418ca268c13826fa2d52",
            "value": 2825034
          }
        },
        "d5ca88ce7b0444b882baeed48db4c499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c7a7ad465b41ca82a23ae5570e75b7",
            "placeholder": "​",
            "style": "IPY_MODEL_0616912951974b33835af84ec230804b",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 6.87MB/s]"
          }
        },
        "886858947f4a40ad93f2f5b285b698bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3970522ad6454c728dc31f790d97d701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b688d7d19f34b158c7f8390b5c01192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c08dd39ce39c4b0ba07b208de9c8577e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be35c569d27418ca268c13826fa2d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15c7a7ad465b41ca82a23ae5570e75b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0616912951974b33835af84ec230804b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f95564a28544477891b7c6d9053852b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d42c9b0c2c7a45faa99126ad1ecb5ce5",
              "IPY_MODEL_7d7945db07e54599a6d6363db7308810",
              "IPY_MODEL_0579c0816b774a8c81ba800e48e4624b"
            ],
            "layout": "IPY_MODEL_c896c8eebe5f48e1922702ec552c602b"
          }
        },
        "d42c9b0c2c7a45faa99126ad1ecb5ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d04934c12ee4e0e852416fbc572e658",
            "placeholder": "​",
            "style": "IPY_MODEL_7a2a4c526c6649ff93831ef5e9dfa50c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7d7945db07e54599a6d6363db7308810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_494cb8d618b04ec4953fe826ed263a55",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7186ea12c6344209b64aa1b5b9dd58cd",
            "value": 1000
          }
        },
        "0579c0816b774a8c81ba800e48e4624b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8c3bcd2a794c09a72b145a6d231bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_e11459ecd83c47a19dcc8c15767c113a",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 80.9kB/s]"
          }
        },
        "c896c8eebe5f48e1922702ec552c602b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d04934c12ee4e0e852416fbc572e658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2a4c526c6649ff93831ef5e9dfa50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "494cb8d618b04ec4953fe826ed263a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7186ea12c6344209b64aa1b5b9dd58cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed8c3bcd2a794c09a72b145a6d231bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11459ecd83c47a19dcc8c15767c113a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56ef3a08b58c4e3f8343a54d2f766e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba11a81ed5c24ec7ad1d5c9a42b85ab6",
              "IPY_MODEL_43d95257fe414a8da4605e9c19e5b0ed",
              "IPY_MODEL_71f144c973944e98a80ec9a8c8133b24"
            ],
            "layout": "IPY_MODEL_5e4fe83a430546318b3f6aec831afb8c"
          }
        },
        "ba11a81ed5c24ec7ad1d5c9a42b85ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88e5a8b237b94edea4fd9aa9cf841510",
            "placeholder": "​",
            "style": "IPY_MODEL_8935f6c4c0bc44f881e131ef07bcec28",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "43d95257fe414a8da4605e9c19e5b0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f24ea6dd4a74ddaa6f05439759bcbc7",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20e15f0ff042417f9ce53b2f0f206f76",
            "value": 513302779
          }
        },
        "71f144c973944e98a80ec9a8c8133b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3ad906736b482489b5ba23963a5837",
            "placeholder": "​",
            "style": "IPY_MODEL_15c282bccc924b249ec84af1d1941acd",
            "value": " 513M/513M [00:01&lt;00:00, 404MB/s]"
          }
        },
        "5e4fe83a430546318b3f6aec831afb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e5a8b237b94edea4fd9aa9cf841510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8935f6c4c0bc44f881e131ef07bcec28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f24ea6dd4a74ddaa6f05439759bcbc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e15f0ff042417f9ce53b2f0f206f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3ad906736b482489b5ba23963a5837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c282bccc924b249ec84af1d1941acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Classymotion/Smilegate/blob/main/gpt2_fine_tuning_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HD80hoYI8dAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d6a320-4125-4ea8-fa5b-01b67e537eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "qa_pairs = [\n",
        "['Q: How to delete the account A: IOS: Go to settings on the app, click on Edit, Click on Logout, Delete the Account Android: Go to settings, Click on the three dots, Click on Logout, Delete the Account.'],\n",
        "['Q: How to deactivate my account A: IOS: Go to settings on the app, click on Edit, Click on Logout, Delete the Account Android: Go to settings, Click on the three dots, Click on Logout, Delete the Account.'],\n",
        "['Q: How i can remove my nmbr A: IOS: Go to settings on the app, click on Edit, Click on Logout, Delete the Account Android: Go to settings, Click on the three dots, Click on Logout, Delete the Account.'],\n",
        "['Q: How to delete an account A: IOS: Go to settings on the app, click on Edit, Click on Logout, Delete the Account Android: Go to settings, Click on the three dots, Click on Logout, Delete the Account.']\n",
        "]\n",
        "'''\n",
        "qa_pairs = [\n",
        "['Q: 빛보다 빨리 달리려면? A: 에너지가 많이 필요해'],\n",
        "['Q: 미래로 가려면? A: 빛의 속도로 달리면 돼'],\n",
        "['Q: 시간을 거꾸로 돌리려면 A: 그건 불가능해, 빛보다 빨리 달리면 몰라도'],\n",
        "['Q: 시간은 소중한 거니 A: 당근당근 당연한 이야기야']\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "MjiCQKOH87pG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = '''\n",
        "모델링 단계에서 어떤 요소들을 고려해야 하는지?\n",
        "CAE 모델의 정확성을 확인하기 위해 어떤 검증 방법을 사용해야 하는지?\n",
        "모델링에서 일어날 수 있는 오류와 해결책은 무엇인지?\n",
        "모델을 개선하기 위해 어떤 수정 및 보완 작업을 해야 하는지?\n",
        "분석에서 다양한 하중 조건을 고려하기 위한 방법은 무엇인지?\n",
        "모델의 복잡성을 줄이기 위해 어떤 단순화 기법을 사용할 수 있는지?\n",
        "분석 결과를 검증하기 위해 어떤 실험 및 시험 방법을 사용할 수 있는지?\n",
        "분석에서 사용되는 소프트웨어 및 하드웨어의 성능을 최적화하기 위해 어떤 방법을 사용할 수 있는지?\n",
        "모델링과 분석에서 생기는 비용과 시간을 줄이기 위한 방법은 무엇인지?\n",
        "모델링과 분석에서 발생할 수 있는 잠재적 위험에 대해 어떻게 대처할 수 있는지?\n",
        "OLED 모듈 제조 과정에서 가장 중요한 단계는 무엇인가요?\n",
        "모듈 제조에 사용되는 기술적인 장비는 어떤 것들이 있나요?\n",
        "OLED 모듈 제조에서 생기는 주요 문제점과 해결책은 무엇인가요?\n",
        "사용되는 소재는 어떤 것들이 있나요?\n",
        "제조에서 생기는 환경 문제와 이를 해결하기 위한 방법은 무엇인가요?\n",
        "모듈 제조에서 생기는 생산 비용과 이를 줄이기 위한 방법은 무엇인가요?\n",
        "인력 문제와 이를 해결하기 위한 방법은 무엇인가요?\n",
        "제조에서 사용되는 기술적인 장비의 성능을 개선하기 위한 방법은 무엇인가요?\n",
        "OLED 모듈에서 생기는 안전 문제와 이를 해결하기 위한 방법은 무엇인가요?\n",
        "OLED 제조에서 발생하는 폐기물 문제와 이를 해결하기 위한 방법은 무엇인가요?\n",
        "현재 불량이 발생하는 공정과 원인은 무엇인가요?\n",
        "불량이 발생하는 제품의 종류와 빈도는 어떻게 되나요?\n",
        "불량검출하는 방법과 검출율은 어떻게 되나요?\n",
        "원인을 파악하기 위한 분석 도구와 방법은 무엇인가요?\n",
        "작업자의 역할과 책임은 무엇인가요?\n",
        "불량을 줄이기 위한 품질 관리 체계는 어떻게 구성되어 있나요?\n",
        "교육 및 훈련 프로그램은 어떻게 운영되나요?\n",
        "원인을 파악한 후 개선을 위한 대책은 무엇인가요?\n",
        "불량을 예방하기 위한 정기적인 유지보수 및 점검 계획은 어떻게 되나요?\n",
        "신속하게 대응하기 위한 비상 대책은 어떻게 마련되어 있나요?\n",
        "조치를 취하기 위한 절차와 책임 분담 방법은 어떻게 되나요?\n",
        "생산 중단 및 손실을 최소화하기 위한 방법은 무엇인가요?\n",
        "원인 파악 및 대응을 위한 데이터 분석 방법과 도구는 무엇인가요?\n",
        "공정 개선을 위한 R&D 활동은 어떻게 이루어지나요?\n",
        "관련 부서 및 담당자들 간의 의사소통 방법은 어떻게 되나요?\n",
        "작업자들의 자발적인 개선 제안을 촉진하는 방법은 무엇인가요?\n",
        "KPI(성과지표)는 어떻게 설정되고 측정되나요?\n",
        "원인에 따른 개선 대책을 수립하고 이를 실시하기 위한 프로젝트 관리 방법은 무엇인가요?\n",
        "고객과의 커뮤니케이션 방법과 대응 방안은 어떻게 되나요?\n",
        "제조 수율을 높이기 위해서 해야할 일은?\n",
        "'''\n",
        "answers = '''\n",
        "모델링 단계에서는 입력 데이터, 모델 선택, 하이퍼파라미터 조정, 모델 평가 지표 등을 고려해야 한다.\n",
        "CAE 모델의 정확성을 확인하기 위해는 실제 데이터와 비교해볼 수 있는 검증 데이터를 사용하거나, 교차 검증 방법을 사용할 수 있다.\n",
        "모델링에서 일어날 수 있는 오류에는 과적합, 언더피팅, 데이터 편향 등이 있으며, 이를 해결하기 위해 데이터 수집과 전처리, 모델 복잡도 조절, 정규화 등을 고려해야 한다.\n",
        "모델을 개선하기 위해는 새로운 데이터 수집 및 전처리, 하이퍼파라미터 튜닝, 더 좋은 모델 선택 등이 필요하다.\n",
        "분석에서 다양한 하중 조건을 고려하기 위한 방법으로는 각 하중 조건에 대한 시뮬레이션을 진행하거나, 다양한 하중 조건에서 실제 실험을 진행하는 것이 있다.\n",
        "모델의 복잡성을 줄이기 위한 단순화 기법으로는 feature selection, PCA 등이 있다.\n",
        "분석 결과를 검증하기 위한 실험 및 시험 방법으로는 재현성 있는 실험, 교차 검증 등이 있다.\n",
        "소프트웨어 및 하드웨어 성능을 최적화하기 위한 방법으로는 병렬 처리, GPU 가속화, 알고리즘 개선 등이 있다.\n",
        "모델링 및 분석에서 생기는 비용과 시간을 줄이기 위한 방법으로는 적은 양의 데이터를 사용하는 등의 방법이 있다.\n",
        "잠재적 위험 대처 방법으로는 데이터 보안 및 개인정보 보호, 모델 검증 및 검증 데이터 사용 등이 있다.\n",
        "OLED 모듈 제조에서 가장 중요한 단계는 배기공정이다.\n",
        "OLED 모듈 제조에 사용되는 기술적인 장비로는 증착장비, 마스크 정렬 장비, 노광 장비 등이 있다.\n",
        "OLED 모듈 제조에서 주요 문제점으로는 불량 발생, 유기물 안정성, 수명 등이 있으며, 이를 해결하기 위해서는 불량 원인 분석, 안정성 개선, 수명 연장 기술 등이 필요하다.\n",
        "사용되는 소재는 다양하지만 OLED 모듈 제조에서는 유기발광체, 전극, 캐패시터, 유리 등이 사용됩니다.\n",
        "제조에서 생기는 환경 문제를 해결하기 위해 재활용, 에너지 효율적인 공정 등을 적용합니다.\n",
        "모듈 제조에서 생기는 생산 비용을 줄이기 위해 자동화, 최적화된 생산 공정, 저렴한 재료 등을 사용합니다.\n",
        "인력 문제를 해결하기 위해 교육 및 훈련 프로그램, 역량 강화 등을 진행합니다.\n",
        "제조에서 사용되는 기술적인 장비의 성능을 개선하기 위해 IoT 기술, 빅데이터 분석, 인공지능 등을 적용합니다.\n",
        "OLED 모듈에서 생기는 안전 문제를 해결하기 위해 안전 규정을 준수하고 안전한 설계를 적용합니다.\n",
        "OLED 제조에서 발생하는 폐기물 문제를 해결하기 위해 재활용, 제로 웨이스트 생산 등의 방법을 적용합니다.\n",
        "현재 불량이 발생하는 공정과 원인은 제품마다 다를 수 있으므로, 각 제품의 불량 발생 공정을 분석해야 합니다.\n",
        "불량이 발생하는 제품의 종류와 빈도는 생산하는 제품의 종류와 생산량에 따라 다르므로 분석이 필요합니다.\n",
        "불량검출하는 방법과 검출율은 시료 추출, 물리적 검사, 화학적 검사, 영상 분석 등의 방법을 사용하며, 검출율은 제품마다 다릅니다.\n",
        "원인을 파악하기 위한 분석 도구와 방법은 통계적 분석, 품질 이력 추적, 페어링 분석 등이 있습니다.\n",
        "작업자는 품질 관리에 책임을 지며, 역할은 제품 생산 과정에서 생기는 문제를 파악하고 조치하는 것입니다.\n",
        "불량을 줄이기 위한 품질 관리 체계는 정해진 표준에 따라 설계되며, 관리 책임자와 절차, 문서화 등으로 이루어집니다.\n",
        "교육 및 훈련 프로그램은 직무별로 계획되고 실시되며, 실적에 따라 평가 및 개선됩니다.\n",
        "원인 파악을 위해 5W1H, Fishbone 등의 도구를 활용하며, 대책은 PDCA 사이클을 통해 수립됩니다.\n",
        "정기적인 유지보수 및 점검 계획은 설비별로 수립되며, 이에 따라 전략적인 부품 관리가 이루어집니다.\n",
        "비상 대책은 각 상황별로 미리 수립되어 있으며, 이에 따른 역할과 책임이 명확히 설정됩니다.\n",
        "조치를 취하기 위한 절차와 책임 분담 방법은 SOP를 통해 정해지며, 이를 엄격하게 준수합니다.\n",
        "생산 중단 및 손실을 최소화하기 위한 방법으로, 재고 관리, 공정 개선 등의 전략적인 대응이 이루어집니다.\n",
        "데이터 분석 방법과 도구로는 통계학, Six Sigma, Minitab 등이 활용됩니다.\n",
        "공정 개선을 위한 R&D 활동은 혁신적인 기술 개발과 실험 등의 다양한 방법을 활용합니다.\n",
        "관련 부서 및 담당자들 간의 의사소통 방법은 회의, 보고서 등의 다양한 형태로 이루어집니다.\n",
        "작업자들의 자발적인 개선 제안을 촉진하는 방법으로는 KIZ(칭찬, 격려, 제안) 제도 등이 활용됩니다.\n",
        "KPI는 전략적 목표를 달성하기 위한 중요한 성과 지표로 설정되며, 정기적으로 측정 및 분석됩니다.\n",
        "원인에 따른 개선 대책을 수립하고 이를 실시하기 위한 프로젝트 관리 방법으로는 PMBOK, Agile 등의 방법이 활용됩니다.\n",
        "고객과의 커뮤니케이션 방법은 설명회, 고객 만족도 조사 등을 통해 이루어지며, 피드백을 수렴하여 적극적으로 대응합니다.\n",
        "제조 수율을 높이기 위해서는 공정의 안정화, 공정 개선 등이 필요하며, 이를 위해 다양한 방법이 활용됩니다.\n",
        "'''"
      ],
      "metadata": {
        "id": "zqDxkrntT1Ra"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "'''\n",
        "\n",
        "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>') \n",
        "model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "\n",
        "'''\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto'#, low_cpu_mem_usage=True\n",
        ").to(device='cuda', non_blocking=True)\n",
        "'''\n",
        "\n",
        "text = ''\n",
        "'''\n",
        "for question in qa_pairs:\n",
        "  text += f'{question} {tokenizer.eos_token}'\n",
        "'''\n",
        "\n",
        "q_list = questions.lstrip().rstrip().splitlines()\n",
        "a_list = answers.lstrip().rstrip().splitlines()\n",
        "for i in range(40):\n",
        "  text += f'Q:{q_list[i]} A:{a_list[i]} {tokenizer.eos_token}'\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "OpwrDFqU8zd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "df1d579d910343a890b02d0990720f61",
            "b74f54f254f843ef95e204deb9a84351",
            "2a8aaa0b629f4ee18ced954ffec066a2",
            "d5ca88ce7b0444b882baeed48db4c499",
            "886858947f4a40ad93f2f5b285b698bd",
            "3970522ad6454c728dc31f790d97d701",
            "2b688d7d19f34b158c7f8390b5c01192",
            "c08dd39ce39c4b0ba07b208de9c8577e",
            "2be35c569d27418ca268c13826fa2d52",
            "15c7a7ad465b41ca82a23ae5570e75b7",
            "0616912951974b33835af84ec230804b",
            "f95564a28544477891b7c6d9053852b7",
            "d42c9b0c2c7a45faa99126ad1ecb5ce5",
            "7d7945db07e54599a6d6363db7308810",
            "0579c0816b774a8c81ba800e48e4624b",
            "c896c8eebe5f48e1922702ec552c602b",
            "9d04934c12ee4e0e852416fbc572e658",
            "7a2a4c526c6649ff93831ef5e9dfa50c",
            "494cb8d618b04ec4953fe826ed263a55",
            "7186ea12c6344209b64aa1b5b9dd58cd",
            "ed8c3bcd2a794c09a72b145a6d231bd5",
            "e11459ecd83c47a19dcc8c15767c113a",
            "56ef3a08b58c4e3f8343a54d2f766e15",
            "ba11a81ed5c24ec7ad1d5c9a42b85ab6",
            "43d95257fe414a8da4605e9c19e5b0ed",
            "71f144c973944e98a80ec9a8c8133b24",
            "5e4fe83a430546318b3f6aec831afb8c",
            "88e5a8b237b94edea4fd9aa9cf841510",
            "8935f6c4c0bc44f881e131ef07bcec28",
            "0f24ea6dd4a74ddaa6f05439759bcbc7",
            "20e15f0ff042417f9ce53b2f0f206f76",
            "fc3ad906736b482489b5ba23963a5837",
            "15c282bccc924b249ec84af1d1941acd"
          ]
        },
        "outputId": "0c09125e-dd5d-49b6-ea9a-10e2a9a36725"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df1d579d910343a890b02d0990720f61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f95564a28544477891b7c6d9053852b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1322: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56ef3a08b58c4e3f8343a54d2f766e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q:모델링 단계에서 어떤 요소들을 고려해야 하는지? A:모델링 단계에서는 입력 데이터, 모델 선택, 하이퍼파라미터 조정, 모델 평가 지표 등을 고려해야 한다. </s>Q:CAE 모델의 정확성을 확인하기 위해 어떤 검증 방법을 사용해야 하는지? A:CAE 모델의 정확성을 확인하기 위해는 실제 데이터와 비교해볼 수 있는 검증 데이터를 사용하거나, 교차 검증 방법을 사용할 수 있다. </s>Q:모델링에서 일어날 수 있는 오류와 해결책은 무엇인지? A:모델링에서 일어날 수 있는 오류에는 과적합, 언더피팅, 데이터 편향 등이 있으며, 이를 해결하기 위해 데이터 수집과 전처리, 모델 복잡도 조절, 정규화 등을 고려해야 한다. </s>Q:모델을 개선하기 위해 어떤 수정 및 보완 작업을 해야 하는지? A:모델을 개선하기 위해는 새로운 데이터 수집 및 전처리, 하이퍼파라미터 튜닝, 더 좋은 모델 선택 등이 필요하다. </s>Q:분석에서 다양한 하중 조건을 고려하기 위한 방법은 무엇인지? A:분석에서 다양한 하중 조건을 고려하기 위한 방법으로는 각 하중 조건에 대한 시뮬레이션을 진행하거나, 다양한 하중 조건에서 실제 실험을 진행하는 것이 있다. </s>Q:모델의 복잡성을 줄이기 위해 어떤 단순화 기법을 사용할 수 있는지? A:모델의 복잡성을 줄이기 위한 단순화 기법으로는 feature selection, PCA 등이 있다. </s>Q:분석 결과를 검증하기 위해 어떤 실험 및 시험 방법을 사용할 수 있는지? A:분석 결과를 검증하기 위한 실험 및 시험 방법으로는 재현성 있는 실험, 교차 검증 등이 있다. </s>Q:분석에서 사용되는 소프트웨어 및 하드웨어의 성능을 최적화하기 위해 어떤 방법을 사용할 수 있는지? A:소프트웨어 및 하드웨어 성능을 최적화하기 위한 방법으로는 병렬 처리, GPU 가속화, 알고리즘 개선 등이 있다. </s>Q:모델링과 분석에서 생기는 비용과 시간을 줄이기 위한 방법은 무엇인지? A:모델링 및 분석에서 생기는 비용과 시간을 줄이기 위한 방법으로는 적은 양의 데이터를 사용하는 등의 방법이 있다. </s>Q:모델링과 분석에서 발생할 수 있는 잠재적 위험에 대해 어떻게 대처할 수 있는지? A:잠재적 위험 대처 방법으로는 데이터 보안 및 개인정보 보호, 모델 검증 및 검증 데이터 사용 등이 있다. </s>Q:OLED 모듈 제조 과정에서 가장 중요한 단계는 무엇인가요? A:OLED 모듈 제조에서 가장 중요한 단계는 배기공정이다. </s>Q:모듈 제조에 사용되는 기술적인 장비는 어떤 것들이 있나요? A:OLED 모듈 제조에 사용되는 기술적인 장비로는 증착장비, 마스크 정렬 장비, 노광 장비 등이 있다. </s>Q:OLED 모듈 제조에서 생기는 주요 문제점과 해결책은 무엇인가요? A:OLED 모듈 제조에서 주요 문제점으로는 불량 발생, 유기물 안정성, 수명 등이 있으며, 이를 해결하기 위해서는 불량 원인 분석, 안정성 개선, 수명 연장 기술 등이 필요하다. </s>Q:사용되는 소재는 어떤 것들이 있나요? A:사용되는 소재는 다양하지만 OLED 모듈 제조에서는 유기발광체, 전극, 캐패시터, 유리 등이 사용됩니다. </s>Q:제조에서 생기는 환경 문제와 이를 해결하기 위한 방법은 무엇인가요? A:제조에서 생기는 환경 문제를 해결하기 위해 재활용, 에너지 효율적인 공정 등을 적용합니다. </s>Q:모듈 제조에서 생기는 생산 비용과 이를 줄이기 위한 방법은 무엇인가요? A:모듈 제조에서 생기는 생산 비용을 줄이기 위해 자동화, 최적화된 생산 공정, 저렴한 재료 등을 사용합니다. </s>Q:인력 문제와 이를 해결하기 위한 방법은 무엇인가요? A:인력 문제를 해결하기 위해 교육 및 훈련 프로그램, 역량 강화 등을 진행합니다. </s>Q:제조에서 사용되는 기술적인 장비의 성능을 개선하기 위한 방법은 무엇인가요? A:제조에서 사용되는 기술적인 장비의 성능을 개선하기 위해 IoT 기술, 빅데이터 분석, 인공지능 등을 적용합니다. </s>Q:OLED 모듈에서 생기는 안전 문제와 이를 해결하기 위한 방법은 무엇인가요? A:OLED 모듈에서 생기는 안전 문제를 해결하기 위해 안전 규정을 준수하고 안전한 설계를 적용합니다. </s>Q:OLED 제조에서 발생하는 폐기물 문제와 이를 해결하기 위한 방법은 무엇인가요? A:OLED 제조에서 발생하는 폐기물 문제를 해결하기 위해 재활용, 제로 웨이스트 생산 등의 방법을 적용합니다. </s>Q:현재 불량이 발생하는 공정과 원인은 무엇인가요? A:현재 불량이 발생하는 공정과 원인은 제품마다 다를 수 있으므로, 각 제품의 불량 발생 공정을 분석해야 합니다. </s>Q:불량이 발생하는 제품의 종류와 빈도는 어떻게 되나요? A:불량이 발생하는 제품의 종류와 빈도는 생산하는 제품의 종류와 생산량에 따라 다르므로 분석이 필요합니다. </s>Q:불량검출하는 방법과 검출율은 어떻게 되나요? A:불량검출하는 방법과 검출율은 시료 추출, 물리적 검사, 화학적 검사, 영상 분석 등의 방법을 사용하며, 검출율은 제품마다 다릅니다. </s>Q:원인을 파악하기 위한 분석 도구와 방법은 무엇인가요? A:원인을 파악하기 위한 분석 도구와 방법은 통계적 분석, 품질 이력 추적, 페어링 분석 등이 있습니다. </s>Q:작업자의 역할과 책임은 무엇인가요? A:작업자는 품질 관리에 책임을 지며, 역할은 제품 생산 과정에서 생기는 문제를 파악하고 조치하는 것입니다. </s>Q:불량을 줄이기 위한 품질 관리 체계는 어떻게 구성되어 있나요? A:불량을 줄이기 위한 품질 관리 체계는 정해진 표준에 따라 설계되며, 관리 책임자와 절차, 문서화 등으로 이루어집니다. </s>Q:교육 및 훈련 프로그램은 어떻게 운영되나요? A:교육 및 훈련 프로그램은 직무별로 계획되고 실시되며, 실적에 따라 평가 및 개선됩니다. </s>Q:원인을 파악한 후 개선을 위한 대책은 무엇인가요? A:원인 파악을 위해 5W1H, Fishbone 등의 도구를 활용하며, 대책은 PDCA 사이클을 통해 수립됩니다. </s>Q:불량을 예방하기 위한 정기적인 유지보수 및 점검 계획은 어떻게 되나요? A:정기적인 유지보수 및 점검 계획은 설비별로 수립되며, 이에 따라 전략적인 부품 관리가 이루어집니다. </s>Q:신속하게 대응하기 위한 비상 대책은 어떻게 마련되어 있나요? A:비상 대책은 각 상황별로 미리 수립되어 있으며, 이에 따른 역할과 책임이 명확히 설정됩니다. </s>Q:조치를 취하기 위한 절차와 책임 분담 방법은 어떻게 되나요? A:조치를 취하기 위한 절차와 책임 분담 방법은 SOP를 통해 정해지며, 이를 엄격하게 준수합니다. </s>Q:생산 중단 및 손실을 최소화하기 위한 방법은 무엇인가요? A:생산 중단 및 손실을 최소화하기 위한 방법으로, 재고 관리, 공정 개선 등의 전략적인 대응이 이루어집니다. </s>Q:원인 파악 및 대응을 위한 데이터 분석 방법과 도구는 무엇인가요? A:데이터 분석 방법과 도구로는 통계학, Six Sigma, Minitab 등이 활용됩니다. </s>Q:공정 개선을 위한 R&D 활동은 어떻게 이루어지나요? A:공정 개선을 위한 R&D 활동은 혁신적인 기술 개발과 실험 등의 다양한 방법을 활용합니다. </s>Q:관련 부서 및 담당자들 간의 의사소통 방법은 어떻게 되나요? A:관련 부서 및 담당자들 간의 의사소통 방법은 회의, 보고서 등의 다양한 형태로 이루어집니다. </s>Q:작업자들의 자발적인 개선 제안을 촉진하는 방법은 무엇인가요? A:작업자들의 자발적인 개선 제안을 촉진하는 방법으로는 KIZ(칭찬, 격려, 제안) 제도 등이 활용됩니다. </s>Q:KPI(성과지표)는 어떻게 설정되고 측정되나요? A:KPI는 전략적 목표를 달성하기 위한 중요한 성과 지표로 설정되며, 정기적으로 측정 및 분석됩니다. </s>Q:원인에 따른 개선 대책을 수립하고 이를 실시하기 위한 프로젝트 관리 방법은 무엇인가요? A:원인에 따른 개선 대책을 수립하고 이를 실시하기 위한 프로젝트 관리 방법으로는 PMBOK, Agile 등의 방법이 활용됩니다. </s>Q:고객과의 커뮤니케이션 방법과 대응 방안은 어떻게 되나요? A:고객과의 커뮤니케이션 방법은 설명회, 고객 만족도 조사 등을 통해 이루어지며, 피드백을 수렴하여 적극적으로 대응합니다. </s>Q:제조 수율을 높이기 위해서 해야할 일은? A:제조 수율을 높이기 위해서는 공정의 안정화, 공정 개선 등이 필요하며, 이를 위해 다양한 방법이 활용됩니다. </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "Ot4MiD6E9rc8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
      ],
      "metadata": {
        "id": "4JKXbYO49xO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078bb643-ccbd-4937-d76b-cdaaac56031a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "m397aLbR94FV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab305a6-063a-4a99-cd01-b9295b46dc26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1000):\n",
        "  optimizer.zero_grad()\n",
        "  loss = model(input_ids.to(device), labels=input_ids.to(device))[0]\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch {epoch}, Loss {loss.item()}')\n"
      ],
      "metadata": {
        "id": "p9wZqqLvOvzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "983aa57e-032e-4d91-e75f-95e8e814e87b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-594e147ed6fc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 )\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    900\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "Olf7E433-uB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question):\n",
        "  # Encode the question using the tokenizer\n",
        "  #input_ids = tokenizer.encode(question + \" <|question|>\", add_special_tokens=False, return_tensors='pt').to(device)\n",
        "  input_ids = tokenizer.encode(question + \":\", add_special_tokens=False, return_tensors='pt').to(device)\n",
        "\n",
        "  # Generate the answer using the model\n",
        "  sample_output = model.generate(input_ids, do_sample=True, max_length=100, top_k=20, top_p=1.0)\n",
        "\n",
        "  # Decode the generated answer using the tokenizer\n",
        "  answer = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "\n",
        "  # Split the generated answer into individual sentences\n",
        "  sentences = answer.split('. ')\n",
        "\n",
        "  # Look for the sentence that contains the answer to the question\n",
        "  for sentence in sentences:\n",
        "      if question in sentence:\n",
        "          return sentence\n",
        "\n",
        "  # If no sentence contains the answer, return the full generated answer\n",
        "  return answer"
      ],
      "metadata": {
        "id": "KXOVt5FC--B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  question = '문재인대통령은 오늘'\n",
        "  response = generate_response(question)\n",
        "  print(f'{response}')\n"
      ],
      "metadata": {
        "id": "peanJ_4X_Ptc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
